{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninay03/Ai-Powered-Predictive-Maintenance-System-for-Renewable-Energy-Plants/blob/main/Wind_Power_Plant_Trained_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A3C0Rom-CHG9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Wn_r-QqNC1O-"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/merged_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BE_w0zqUC9bD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1e11b2-9da2-4017-8cbd-01d322c8e8e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['dia_mes_ano', 'hora_minuto', 'irr', 'massaPM1', 'massaPM2', 'massaPM4',\n",
              "       'massaPM10', 'numPM1', 'numPM2', 'numPM4', 'numPM10', 'tamanho_medio',\n",
              "       'temp', 'vento_dir', 'vento_vel', 'rainfall'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YkRQimUnF2sW"
      },
      "outputs": [],
      "source": [
        "df = data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "em3FXVigLjYF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# Step 1: Load and Preprocess Data\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/merged_dataset.csv')\n",
        "\n",
        "# Convert datetime\n",
        "\n",
        "df['dia_mes_ano'] = pd.to_datetime(df['dia_mes_ano'], format='%Y%m%d')\n",
        "\n",
        "# Ensure hora_minuto is six digits long\n",
        "\n",
        "df['hora_minuto'] = df['hora_minuto'].apply(lambda x: f\"{int(x):06d}\")\n",
        "df['hora_minuto'] = pd.to_datetime(df['hora_minuto'], format='%H%M%S').dt.time\n",
        "\n",
        "# Extract time features\n",
        "\n",
        "df['hour'] = pd.to_datetime(df['hora_minuto'].astype(str), format='%H:%M:%S').dt.hour\n",
        "df['day_of_week'] = df['dia_mes_ano'].dt.dayofweek\n",
        "df['month'] = df['dia_mes_ano'].dt.month\n",
        "\n",
        "# Drop original datetime columns\n",
        "\n",
        "df = df.drop(['dia_mes_ano', 'hora_minuto'], axis=1)\n",
        "\n",
        "# Step 2: Calculate Health Score\n",
        "\n",
        "# Handle missing historical data in expected_irr\n",
        "\n",
        "expected_irr = df.groupby(['month', 'hour'])['irr'].transform('mean')\n",
        "expected_irr = expected_irr.fillna(df['irr'].mean())\n",
        "\n",
        "PM10_THRESHOLD = 25\n",
        "\n",
        "# Calculate health_score (handle division by zero)\n",
        "\n",
        "df['health_score'] = (df['irr'] / expected_irr.replace(0, 1e-6)) * (1 - (df['massaPM10'] / PM10_THRESHOLD))\n",
        "df['health_score'] = np.clip(df['health_score'], 0, 1)\n",
        "\n",
        "# Drop rows with NaN in health_score\n",
        "\n",
        "df = df.dropna(subset=['health_score'])\n",
        "\n",
        "\n",
        "# Step 3: Train Model\n",
        "\n",
        "X = df.drop('health_score', axis=1)\n",
        "y = df['health_score']\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RqGHZdO9em84"
      },
      "outputs": [],
      "source": [
        "model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=4,\n",
        "    max_features='sqrt',  # Consider sqrt(features) at each split\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oquu_ihjerG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46dcefa9-d3b3-4a81-9fe6-1f4557ea5280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score: 0.9296\n",
            "Mean Absolute Error: 0.0657\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Step 4: Evaluate Model\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # For when deployed to Real Time data\n",
        "\n",
        " def predict_health_score():\n",
        "      json_input = input(\"Enter the input data as a JSON object: \")\n",
        "\n",
        "      try:\n",
        "          data = json.loads(json_input)  # Parse JSON input\n",
        "\n",
        "          # Required keys\n",
        "          required_keys = [\n",
        "              'irr', 'massaPM1', 'massaPM2', 'massaPM4', 'massaPM10',\n",
        "              'numPM1', 'numPM2', 'numPM4', 'hour', 'day_of_week', 'month',\n",
        "              'numPM10', 'rainfall', 'tamanho_medio', 'temp', 'vento_dir', 'vento_vel'\n",
        "          ]\n",
        "\n",
        "          # Check if all required keys are present\n",
        "          if not all(key in data for key in required_keys):\n",
        "              missing_keys = [key for key in required_keys if key not in data]\n",
        "              print(f\"Missing keys in input JSON: {missing_keys}\")\n",
        "              return\n",
        "\n",
        "          # Prepare input for prediction\n",
        "          input_data = pd.DataFrame([data])\n",
        "\n",
        "          # Prediction\n",
        "          prediction = model.predict(input_data)\n",
        "          print(f\"\\nPredicted Health Score: {prediction[0]:.4f}\")\n",
        "\n",
        "      except json.JSONDecodeError:\n",
        "          print(\"Invalid JSON format. Please enter a valid JSON object.\")"
      ],
      "metadata": {
        "id": "YooFlwjDChzy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW7jgnLUNrGo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler # Import the StandardScaler\n",
        "\n",
        "def predict_health_score():\n",
        "\n",
        "    scaler_X = StandardScaler()\n",
        "    scaler_X.fit(X)\n",
        "\n",
        "    scaler_y = StandardScaler()  # Initialize for y\n",
        "    y_reshaped = y.values.reshape(-1, 1)  # Reshape for scaler\n",
        "    scaler_y.fit(y_reshaped)\n",
        "\n",
        "    # Collect input values manually\n",
        "    dia_mes_ano = input(\"Enter dia_mes_ano: \")\n",
        "    hora_minuto = input(\"Enter hora_minuto: \")\n",
        "    irr = float(input(\"Enter irr: \"))\n",
        "    massaPM1 = float(input(\"Enter massaPM1: \"))\n",
        "    massaPM2 = float(input(\"Enter massaPM2: \"))\n",
        "    massaPM4 = float(input(\"Enter massaPM4: \"))\n",
        "    massaPM10 = float(input(\"Enter massaPM10: \"))\n",
        "    numPM1 = float(input(\"Enter numPM1: \"))\n",
        "    numPM2 = float(input(\"Enter numPM2: \"))\n",
        "    numPM4 = float(input(\"Enter numPM4: \"))\n",
        "    numPM10 = float(input(\"Enter numPM10: \"))\n",
        "    tamanho_medio = float(input(\"Enter tamanho_medio: \"))\n",
        "    temp = float(input(\"Enter temp: \"))\n",
        "    vento_dir = float(input(\"Enter vento_dir: \"))\n",
        "    vento_vel = float(input(\"Enter vento_vel: \"))\n",
        "    rainfall = float(input(\"Enter rainfall: \"))\n",
        "\n",
        "    # Create input DataFrame (excluding date & time since they may not be used in prediction)\n",
        "    input_data = pd.DataFrame([[\n",
        "        irr, massaPM1, massaPM2, massaPM4, massaPM10,\n",
        "        numPM1, numPM2, numPM4, numPM10, tamanho_medio,\n",
        "        temp, vento_dir, vento_vel, rainfall\n",
        "    ]], columns=[\n",
        "        'irr', 'massaPM1', 'massaPM2', 'massaPM4', 'massaPM10',\n",
        "        'numPM1', 'numPM2', 'numPM4', 'numPM10', 'tamanho_medio',\n",
        "        'temp', 'vento_dir', 'vento_vel', 'rainfall'\n",
        "    ])\n",
        "\n",
        "    # Scale the input data\n",
        "    input_scaled = scaler_X.transform(input_data)\n",
        "\n",
        "    # Reshape for LSTM\n",
        "    input_scaled = np.reshape(input_scaled, (input_scaled.shape[0], 1, input_scaled.shape[1]))\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_scaled)\n",
        "\n",
        "    # Inverse transform the prediction\n",
        "    predicted_score = scaler_y.inverse_transform(prediction)\n",
        "\n",
        "    print(f\"\\nPredicted Health Score: {predicted_score[0][0]:.4f}\")\n",
        "\n",
        "# Call function\n",
        "predict_health_score()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UqER8IM7fRHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b094f3f8-79a5-4f0d-f786-a5b7088ffb85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wind_energy_trained_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the feature order\n",
        "feature_order = X_train.columns.tolist()\n",
        "\n",
        "# Save model and feature order together\n",
        "joblib.dump((model, feature_order), \"wind_energy_trained_model.pkl\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "azzHFt5Apo2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff988d8d-7360-45ca-e46a-dd1696479812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score: 0.9296\n",
            "Mean Absolute Error: 0.0657\n",
            "Model saved successfully as wind_energy_trained_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Step 1: Load and Preprocess Data\n",
        "df = pd.read_csv('/content/merged_dataset.csv')\n",
        "\n",
        "# Convert datetime\n",
        "df['dia_mes_ano'] = pd.to_datetime(df['dia_mes_ano'], format='%Y%m%d')\n",
        "\n",
        "# Ensure 'hora_minuto' is formatted correctly\n",
        "df['hora_minuto'] = df['hora_minuto'].apply(lambda x: f\"{int(x):06d}\")\n",
        "df['hora_minuto'] = pd.to_datetime(df['hora_minuto'], format='%H%M%S').dt.time\n",
        "\n",
        "# Extract time features\n",
        "df['hour'] = pd.to_datetime(df['hora_minuto'].astype(str), format='%H:%M:%S').dt.hour\n",
        "df['day_of_week'] = df['dia_mes_ano'].dt.dayofweek\n",
        "df['month'] = df['dia_mes_ano'].dt.month\n",
        "\n",
        "# Drop original datetime columns\n",
        "df = df.drop(['dia_mes_ano', 'hora_minuto'], axis=1)\n",
        "\n",
        "# Step 2: Calculate Health Score\n",
        "expected_irr = df.groupby(['month', 'hour'])['irr'].transform('mean')\n",
        "expected_irr = expected_irr.fillna(df['irr'].mean())\n",
        "\n",
        "PM10_THRESHOLD = 25\n",
        "df['health_score'] = (df['irr'] / expected_irr.replace(0, 1e-6)) * (1 - (df['massaPM10'] / PM10_THRESHOLD))\n",
        "df['health_score'] = np.clip(df['health_score'], 0, 1)\n",
        "\n",
        "# Drop rows with NaN in health_score\n",
        "df = df.dropna(subset=['health_score'])\n",
        "\n",
        "# Step 3: Train Model\n",
        "X = df.drop('health_score', axis=1)\n",
        "y = df['health_score']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest Model\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=4,\n",
        "    max_features='sqrt',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Evaluate Model\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "\n",
        "# Step 5: Save Model as Pickle File\n",
        "model_filename = \"wind_energy_trained_model.pkl\"\n",
        "joblib.dump((model, X_train.columns.tolist()), model_filename)\n",
        "\n",
        "print(f\"Model saved successfully as {model_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Cn3o3LdgpqMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a68e61-3249-44ad-fca3-66ca02f7ae59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the input data as a JSON object: 20191018\t800\t0\t8.38\t0.28\t0\t0\t69.11\t0.19\t0\t0\t0.47\t24\t45\t9.31\t0\n",
            "Invalid JSON format. Please enter a valid JSON object.\n"
          ]
        }
      ],
      "source": [
        "# Load the trained model\n",
        "def load_model():\n",
        "    model_filename = \"wind_energy_trained_model.pkl\"\n",
        "    loaded_model, feature_order = joblib.load(model_filename)\n",
        "    return loaded_model, feature_order\n",
        "\n",
        "# Predict Health Score\n",
        "def predict_health_score():\n",
        "    json_input = input(\"Enter the input data as a JSON object: \")\n",
        "\n",
        "    try:\n",
        "        data = json.loads(json_input)  # Parse JSON input\n",
        "        model, feature_order = load_model()\n",
        "\n",
        "        # Required keys (ensure they match feature names exactly)\n",
        "        required_keys = feature_order\n",
        "\n",
        "        # Check if all required keys are present\n",
        "        missing_keys = [key for key in required_keys if key not in data]\n",
        "        if missing_keys:\n",
        "            print(f\"Missing keys in input JSON: {missing_keys}\")\n",
        "            return\n",
        "\n",
        "        # Convert JSON to DataFrame\n",
        "        input_data = pd.DataFrame([data])\n",
        "\n",
        "        # Ensure correct feature order\n",
        "        input_data = input_data[feature_order]\n",
        "\n",
        "        # Make Prediction\n",
        "        prediction = model.predict(input_data)\n",
        "        print(f\"\\nPredicted Health Score: {prediction[0]:.4f}\")\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Invalid JSON format. Please enter a valid JSON object.\")\n",
        "\n",
        "# Run Prediction\n",
        "predict_health_score()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNehCeK6IptyxlDXEMfy6zK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}